{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                        SLUČAJNE ŠUME\n",
    "                                        \n",
    "   Postoje različiti pristupi  mašinskom učenju, a jedan od njih uključuje veći broj modela koji zajednički donose odluke. Osnovna ideja koja se krije iza ovog pristupa je da su 'dve glave pametnije od jedne', odnosno\n",
    "više modela omogućavaju bolju precinost nego jedan.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metod slučajnih šuma je zasnovan na prostoj agregaciji stabala odlučivanja. \n",
    "Svaki čvor stabla sadrži po jedan test koji očekuje više od jednog ishoda.\n",
    "A svakom ishodu  odgovara jedna grana stabla koja vodi ka sledećem čvoru. \n",
    "U listovima se ne nalaze testovi već u njima se nalaze predviđanja.\n",
    "Jasno je da šumu čine više ovakvih stabala testiranih na različitim podskupovima skupa za obučavanje. \n",
    "Bitno je da se svako stablo obučava na različitom podskupu kako bi greške bili slabije korelisane.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za početak razmotrićemo šta nam biblioteka scikit-learn nudi..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "y = data['Outcome']\n",
    "X = data.drop(columns=['Outcome'], axis=1 )\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, stratify=y, random_state = 7)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7598425196850394"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = ensemble.RandomForestClassifier(n_estimators=20, max_depth=3, random_state=7)\n",
    "model_forest.fit(X_train, y_train)\n",
    "y_predicted = model_forest.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from math import sqrt\n",
    "from random import randrange\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random subsample from the dataset with replacement\n",
    "#slučajni podskup\n",
    "def subsample(dataset, ratio):\n",
    "    sample = list()\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    while len(sample) < n_sample:\n",
    "        index = randrange(len(dataset))\n",
    "        sample.append(dataset[index])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Koristicemo Ginijev indeks kao meru homogenosti skupa instanci.\n",
    "     Ovaj pristup pociva na udelima isntanci razlicitih klasa u ukupnom skupu.\n",
    " Ginijev indeks je definisan formulom: \n",
    " G(p1, p2, ..., pk) = 1 - (p1^2 + p2^2 + ... + pk^2) = 1 - sum(pi^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giniIndex(groups,classes):\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    Gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0.0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p*p\n",
    "        Gini += (1.0-score) * (size / n_instances)\n",
    "    return Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delimo podatke\n",
    "def testSplit(index,value,dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index]< value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pomocu Ginjevog indeksa biramo najbolji tacku za podelu skupa podataka\n",
    "def getSplitForest(dataset, n_attributes):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    attributes = list()\n",
    "    while len(attributes) < n_attributes:\n",
    "        index = randrange(len(dataset[0])-1)\n",
    "        if index not in attributes:\n",
    "            attributes.append(index)\n",
    "    for index in attributes:\n",
    "        for row in dataset:\n",
    "            groups = testSplit(index, row[index], dataset)\n",
    "            Gini = giniIndex(groups, class_values)\n",
    "            #print('X%d < %.3f Gini=%.3f' % ((index+1), row[index], Gini))\n",
    "            if Gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], Gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formiramo vrednost zavrsnog svora\n",
    "def toTerminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcija za deljenje cvorova\n",
    "def splitNodeForest(node, max_depth, min_size, n_attributes, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = toTerminal(left + right)\n",
    "        return\n",
    "    #pravimo zavrsni cvor ukoliko smo dosli do maksimalne dubine\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = toTerminal(left), toTerminal(right)\n",
    "        return\n",
    "    #proveravamo da li je postignuta minimalna veličina ili je potrebno dodatno račvanje stabla\n",
    "    \n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = toTerminal(left)\n",
    "    else:\n",
    "        node['left'] = getSplitForest(left, n_attributes)\n",
    "        splitNodeForest(node['left'], max_depth, min_size, n_attributes,depth+1)\n",
    "   \n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = toTerminal(right)\n",
    "    else:\n",
    "        node['right'] = getSplitForest(right, n_attributes)\n",
    "        splitNodeForest(node['right'], max_depth, min_size, n_attributes,  depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formiramo stablo odluke\n",
    "def buildTree(train, max_depth, n_attributes ,min_size):\n",
    "    root = getSplitForest(train, n_attributes)\n",
    "    splitNodeForest(root, max_depth, min_size, n_attributes ,1)\n",
    "    return root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vršimo predikciju na osnovu stabla odluke\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vršimo predikciju na osnovu liste predikcija\n",
    "def baggingPredict(trees, row):\n",
    "    predictions = [predict(tree, row) for tree in trees]\n",
    "    return max(set(predictions), key=predictions.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Algorithm\n",
    "def randomForest(train, test, max_depth, min_size, sample_size, n_trees, n_features):\n",
    "    trees = list()\n",
    "    for _ in range(n_trees):\n",
    "        sample = subsample(train, sample_size)\n",
    "        tree = buildTree(sample, max_depth, min_size, n_features)\n",
    "        trees.append(tree)\n",
    "    predictions = [baggingPredict(trees, row) for row in test]\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Učitavamo fajl, red po red\n",
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## konvertujemo nisku u float\n",
    "def strToFloat(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "#konvertujemo nisku u intidžer\n",
    "def strToInt(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Normalizacija podataka ###########\n",
    "## TODO: dodati teks o kros validaciji\n",
    "##pronalazimo najmanju i najveću vrednost u svakoj koloni\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        colvalues = [row[i] for row in dataset]\n",
    "        min_value = min(colvalues) \n",
    "        max_value = max(colvalues)\n",
    "        minmax.append([min_value, max_value])\n",
    "    return minmax\n",
    "\n",
    "#Normalizujemo skup podataka\n",
    "def Normalize_Dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Kros validacija ###########\n",
    "## TODO: dodati tekst o kros validaciji\n",
    "\n",
    "#delimo skup na k polja - kros validacija\n",
    "def crossValidationSplit(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "\n",
    "# ocenjivanje algoritma koristeci kros-validaciju na dati skup podataka i \n",
    "# i naš randomForest algoritam uz pomoć funkcije za precenu učinka:getAccuracy\n",
    "def evaluateAlgorithm(dataset, algorithm, n_folds, performance_assessment, *args):\n",
    "    folds = crossValidationSplit(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        performance = performance_assessment(actual, predicted)\n",
    "        scores.append(performance)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dobijena tacnost predvidjanja #\n",
    "def getAccuracy(actual,predicted):\n",
    "    correct = 0\n",
    "    for x in range(len(actual)):\n",
    "        if actual[x] == predicted[x]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees: 1\n",
      "Scores: [65.78947368421053, 68.42105263157895, 75.0, 68.42105263157895, 77.63157894736842, 60.526315789473685, 75.0, 68.42105263157895, 76.31578947368422, 65.78947368421053]\n",
      "Mean Accuracy: 70.132%\n",
      "Trees: 2\n",
      "Scores: [73.68421052631578, 63.1578947368421, 76.31578947368422, 69.73684210526315, 80.26315789473685, 72.36842105263158, 72.36842105263158, 72.36842105263158, 65.78947368421053, 75.0]\n",
      "Mean Accuracy: 72.105%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    seed(2)\n",
    "    filename =  'diabetes.csv'\n",
    "    dataset = load_csv(filename)\n",
    "    dataset = dataset[1:] \n",
    "    for i in range(0, len(dataset[0])):\n",
    "        strToFloat(dataset, i)\n",
    "    n_folds = 10\n",
    "    max_depth = 3\n",
    "    min_size = 3.0\n",
    "    sample_size = 3.0\n",
    "    n_features = 20 \n",
    "    for n_trees in [1,2,4,8, 20]:\n",
    "        scores = evaluateAlgorithm(dataset, randomForest, n_folds, getAccuracy,max_depth, min_size, sample_size, n_trees, n_features)\n",
    "        print('Trees: %d' % n_trees)\n",
    "        print('Scores: %s' % scores)\n",
    "        print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
